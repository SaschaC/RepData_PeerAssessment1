}
# test the functions:
matu = matrix(1:4,2,2)
x = makeCacheMatrix(matu); x
cacheSolve(x)
rpois(5,2)
rpois(5,2)
rpois(5,2)
setseed(1)
set.seed(1)
rpois(5,2)
rpois(5,2)
rpois(5,2)
set.seed(1)
rpois(5,2)
updateR()
install.packages("installr"); require(installr) #load / install+load installr
updateR()
swirl()
library(swirl)
swirl()
install_from_swirl("R programming")
swirl()
5+7
updateR()
library(airpollution)
swirl()
10
25
4
summary(cars$price)
swirl()
swirl()
skip()
25
4
summary(cars$price)
library(swirl)
install_from_swirl("R programming")
install_from_swirl("R Programming")
swirl()
5+7
x <- 5+7
x
y <- x-3
y
z <- c(1.1,9,3.14)
?c
z
bye()
swirl()
c(z,555,z)
z*2+100
bye()
library("hdf5")
biocLite("rhdf5")
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library("hdf5")
install.packages("rhdf5")
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library("hdf5")
library("rhdf5")
created = h5createFile("example.h5")
created
created = h5createGroup("example.h5", "foo")
created = h5createGroup("example.h5", "baa")
created = h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5")
h5write(A, "example.h5", "foo/A")
A = matrix(1:10, nr=5, nc=2)
h5write(A, "example.h5", "foo/A")
created = h5createGroup("example.h5", "foo")
h5ls("example.h5") # like ls command
h5write(B, "example.h5", "foo/foobaa/B")
attr(B, "scale") <- "liter"
B = matrix(1:10, nr=5, nc=2)
attr(B, "scale") <- "liter"
h5write(B, "example.h5", "foo/foobaa/B")
h5ls("example.h5") # like ls command
readA= h5read("example.h5","foo/A")
readB= h5read("example.h5","foo/foobaa/B")
readA
h5write(c(1,2,3), "example.h5", "foo/A", index = list(1:3,1))
h5read("example.h5","foo/A")
h5write(c(3,9,3), "example.h5", "foo/A", index = list(1:3,1))
h5read("example.h5","foo/A")
is.na(sub1)
colSums(is.na(sub1))
data(UCBAdmissions)
d = as.dataframe(UCSAdmissions)
d = as.data.frame(UCSAdmissions)
d = as.data.frame(UCBAdmissions)
table(d$Freq, d$Gender)
table(d$Admit, d$Gender)
xtabs(d$Admit~ d$Gender)
xtabs(Admit~ Gender, data = d)
load("~/Arbeit/study/xp1/ws_combined2_xp1.RData")
xtabs(correctness~ red, data = d.sub.05)
xtabs(~ red, data = d.sub.05)
table(d.sub.05$red)
head(average)
average = aggregate(long$value, by = list(long$subject,long$variable, long$activityName, long$activityNumber),mean)
X_test <- read.table("./getdata-projectfiles-UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt", quote="\"")
Y_test <- scan("./getdata-projectfiles-UCI HAR Dataset/UCI HAR Dataset/test/Y_test.txt", quote="\"")
X_train <- read.table("./getdata-projectfiles-UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt", quote="\"")
Y_train <- scan("./getdata-projectfiles-UCI HAR Dataset/UCI HAR Dataset/train/Y_train.txt", quote="\"")
subject_train = scan("./getdata-projectfiles-UCI HAR Dataset/UCI HAR Dataset/train/subject_train.txt", quote="\"")
subject_test = scan("./getdata-projectfiles-UCI HAR Dataset/UCI HAR Dataset/test/subject_test.txt", quote="\"")
activity_labels = read.table("./getdata-projectfiles-UCI HAR Dataset/UCI HAR Dataset/activity_labels.txt", quote="\"")
activityNumber = c(Y_train, Y_test)
subjects = c(subject_train, subject_test)
# Part 1:
d = rbind(X_train, X_test)
## Part 2: Select only feature columns corresponding to mean/std measurements
# first determine the columns, then subset columns:
features = read.table("./getdata-projectfiles-UCI HAR Dataset/UCI HAR Dataset/features.txt", quote="\"")
feature_names = features[,2]
mean_features = grep("mean()", feature_names)
std_features = grep("std()", feature_names)
relevant_columns = c(mean_features, std_features) # vector of 79 numbers corresponding to the relevant columns
sub1 = d[,relevant_columns]
# Part 3: add subjects, activity numbers and names
sub2 = cbind(sub1,activityNumber=activityNumber)
sub2$subject = subjects
sub3 = merge(sub2, activity_labels, by.x = "activityNumber", by.y = "V1")
str(sub3)
## Part 4: formatting column (feature) names
relevant_names = feature_names[relevant_columns];relevant_names # get the relevant names used for subsetting earlier
variable_names = gsub("[^[:alnum:]]", "", relevant_names) # remove all non-alphanumeric characters
variable_names = gsub("BodyBody", "Body", variable_names) # remove reduplications
variable_names = gsub("std", "Std", variable_names) # remove reduplications
variable_names = gsub("mean", "Mean", variable_names) # to ensure uniform formatting
length(variable_names)
colnames(sub3)[2:80] = variable_names
colnames(sub3)[82] = "activityName"
# Part 5: Average table
# first convert table into long format:
long = melt(sub3, id = c("subject","activityNumber", "activityName"), measure.vars = colnames(sub3)[2:80])
# now aggregate over long table:
average = aggregate(long$value, by = list(long$subject,long$variable, long$activityName, long$activityNumber),mean)
average=arrange(average, average$Group.1) # sort the table
colnames(average) = c("subject", "feature", "activityName", "activityNumber", "value")
head(average)
swirl()
library(swirl)
swirl()
swirl()
install_from_swirl("Getting and Cleaning Data")
install_from_swirl("Getting and Cleaning Data")
install_from_swirl("Getting and Cleaning Data")
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf = read.csv(path2csv, stringsAsFactors = F)
mydf = read.csv(path2csv, stringsAsFactors = FALSE)
read.csv(path2csv, stringsAsFactors = FALSE) -> mydf
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(X:size))
cran
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
View(cran)
filter(cran, r_version <= "3.1.1", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500 & r_os == "linux-gnu")
filter(cran, size > 100500 && r_os == "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 = select(cran, size:ip_id)
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package,ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 = select(cran, ip_id, package, size)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20,size_gb = size_mb / 2^10 )
mutate(cran3, correct_size = size -1000 )
mutate(cran3, correct_size = size +1000 )
summarize(cran, avg_by = mean(size) )
summarize(cran, avg_bytes = mean(size) )
swirl()
library(dplyr)
tbl_df(mydf)
tbl_df(mydf) -> cran
rm("mydf")
cran
?group_by()
?group_by
by_package(cran, package)
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean)
summarize(by_package, mean(size))
submit()
?n
submit()
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts = filter(pack_sum, count > 679.56)
top_counts <- filter(pack_sum, count > 679.56)
top_counts <- filter(pack_sum, count > 679)
top_counts
view(top_counts)
View(top_counts)
arrange(top_counts, desc(count))
arrange(top_counts, desc(count))->top_counts_sorted
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_counts = filter(pack_sum, unique> 465)
top_counts <- filter(pack_sum, unique> 465)
top_unique <- filter(pack_sum, unique> 465)
View(top_unique)
arrange(top_unique, desc(unique))->top_unique_sorted
View(top_unique_sorted)
submit()
?n_distinct
submit()
submit()
View(result3)
submit()
submit()
reset()
submit()
submit()
submit()
submit()
submit()
?pnorm
nrow(d)
NEI <- readRDS("../data/summarySCC_PM25.rds")
?sum
sum(c(2,4))
SCC <- readRDS("../data/Source_Classification_Code.rds")
m = matrix(seq(1:4),2,2)
m
m[1,2]
4064.93/(311,9/100)
4064.93/(311.9/100)
1303.28*3 + 1303.28*0.054 + 1303.28*0.039 + 1303.28*0.026
25/166^^
^^25
sqrt(25/16)
2*(-101/16)^2+11*-(101/16)+12
11^2
set_2 <- group_by(d, interval)%>%summarize(average_steps = mean(steps, na.rm = T))
library(dplyr)
setwd("~/RepData_PeerAssessment1")
d <- tbl_df(read.csv('activity.csv'))
setwd("~/Arbeit/courses/coursera/Reproducible Research/Project I/RepData_PeerAssessment1")
d <- tbl_df(read.csv('activity.csv'))
d <- transform(d, date = as.Date(date, "%Y-%m-%d"))
set_1 <- group_by(d, date)%>%summarize(total_steps = sum(steps))
hist(set_1$total_steps)
mean(set_1$total_steps, na.rm = T)
median(set_1$total_steps, na.rm = T)
set_2 <- group_by(d, interval)%>%summarize(average_steps = mean(steps, na.rm = T))
plot(set_2$average_steps ~ set_2$interval, type = "l")
filter(set_2, average_steps == max(average_steps))
sapply(d, function(x) length(which(is.na(x))))
set_2
d[which(is.na(d$interval)),]
d[which(is.na(d$steps)),]
length(d[which(is.na(d$steps)),])
nrow(d[which(is.na(d$steps)),])
??dplyr
function replace_na_with_average(x) {
set_2$average_steps[set_2$interval == x,]
}
x = 1
a = 1
x == a
test = sapply(d$steps, replace_na_with_average, d$interval)
replace_na_with_average <- function (x, y) {
#set_2$average_steps[set_2$interval == x,]
print(y)
}
test = sapply(d$steps, replace_na_with_average, d$interval)
x = c(1,2,3)
seq_along(x)
x = c(1,2,'a')
seq_along(x)
test = sapply(seq_along(d$steps), replace_na_with_average)
replace_na_with_average <- function (index) {
#set_2$average_steps[set_2$interval == x,]
print(index)
}
test = sapply(seq_along(d$steps), replace_na_with_average)
d2 = d[:,:]
d2 = d[:]
d2 = d[:]
d2 <- d[:]
d2 <- d[,]
d2 <- d[,]
est = c(1,2,3)
replace_na_with_average <- function (index) {
set_2[set_2$interval== d2$interval[index],]$steps
}
d2 <- d[,]
sapply(seq_along(d2$steps), function(x) d2$steps[x] <- replace_na_with_average(x) if is.na(d$steps[x]))
replace_na_with_average <- function (index) {
if (is.na(d2$steps[index])) {
set_2[set_2$interval== d2$interval[index],]$steps
}
else {
d2$steps[index]
}
}
sapply(seq_along(d2$steps), function(x) d2$steps[x] <- replace_na_with_average(x))
sapply(seq_along(d2$steps), function(x) d2$steps[x] <- replace_na_with_average(x))
replace_na_with_average <- function (index) {
if (is.na(d2$steps[index])) {
return(set_2[set_2$interval== d2$interval[index],]$steps)
}
else {
return(d2$steps[index])
}
}
sapply(seq_along(d2$steps), function(x) d2$steps[x] <- replace_na_with_average(x))
d2$steps[0]
d2$steps[1]
set_2[set_2$interval== d2$interval[1],]$steps
set_2[set_2$interval== d2$interval[100],]$steps
d2$interval[100]
set_2$interval[100]
d2$interval[100]
d2$interval[1000]
set_2$interval[1000]
set_2[set_2$interval== d2$interval[100],]
set_2[set_2$interval== d2$interval[100],]$average_steps
d2 <- d[,]
replace_na_with_average <- function (index) {
if (is.na(d2$steps[index])) {
return(set_2[set_2$interval== d2$interval[index],]$average_steps)
}
else {
return(d2$steps[index])
}
}
sapply(seq_along(d2$steps), function(index) d2$steps[index] <- replace_na_with_average(x))
d2$steps
str(set_2)
str(group_by(d, interval))
test = group_by(d, interval)
str(test$interval)
names(test$interval)
dim(test$interval)
dimnames(test$interval)
attributes(test$interval)
str(test)
str(d)
sapply(seq_along(d2$steps), function(index) d2$steps[index] <- replace_na_with_average(x))
replace_na_with_average <- function (index) {
if (is.na(d2$steps[index])) {
return(mean(d2$steps[d2$interval==d2$interval[index]]))
}
else {
return(d2$steps[index])
}
}
sapply(seq_along(d2$steps), function(index) d2$steps[index] <- replace_na_with_average(x))
replace_na_with_average <- function (index) {
if (is.na(d2$steps[index])) {
mean(d2$steps[d2$interval==d2$interval[index]], na.rm = T)
}
else {
d2$steps[index]
}
}
sapply(seq_along(d2$steps), function(index) d2$steps[index] <- replace_na_with_average(x))
is.na(d$steps)
str(d2)
replace_na_with_average <- function (index) {
if (is.na(d2$steps[index])) {
return(mean(d2$steps[d2$interval==d2$interval[index]], na.rm = T))
}
else {
return(d2$steps[index])
}
}
sapply(seq_along(d2$steps), function(index) d2$steps[index] <- replace_na_with_average(x))
mean(d2$steps[d2$interval==d2$interval[100]], na.rm = T)
sapply(seq_along(d2$steps), function(index) d2$steps[index] <- replace_na_with_average(index))
d2$steps!=d$steps
d2$steps==d$steps
is.na(d2$steps)
for index in seq_along(d2$steps) {
if (is.na(d2$steps[index])) {
d2$steps[index] <- mean(d2$steps[d2$interval==d2$interval[index]], na.rm = T)
}
}
for (index in seq_along(d2$steps)) {
if (is.na(d2$steps[index])) {
d2$steps[index] <- mean(d2$steps[d2$interval==d2$interval[index]], na.rm = T)
}
}
is.na(d2$steps)
set_3 <- group_by(d2, date)%>%summarize(total_steps = sum(steps))
hist(set_3$total_steps)
hist(set_1$total_steps)
hist(set_3$total_steps)
hist(set_1$total_steps)
hist(set_3$total_steps)
hist(set_1$total_steps)
hist(set_3$total_steps)
mean(set_3$total_steps, na.rm = T)
median(set_3$total_steps, na.rm = T)
mean(set_3$total_steps, na.rm = T)
median(set_3$total_steps, na.rm = T)
mean(set_3$total_steps)
median(set_3$total_steps)
weekdays(d$date[1:10])
d2$part_of_week[weekdays(d2$date)%in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")] = 'weekday'
View(`d2`)
d$part_of_week
d2$part_of_week
d2$part_of_week[weekdays(d2$date)%in% c("Saturday", "Sunday"] = 'weekend'
d2$part_of_week[weekdays(d2$date)%in% c("Saturday", "Sunday")] = 'weekend'
is.na(d2$part_of_week)
whic(is.na(d2$part_of_week))
which(is.na(d2$part_of_week))
library(ggplot2)
set_4 <- group_by(d2, c(interval, part_of_week))%>%summarize(average_steps = mean(steps))
??dplyr
set_4 <- group_by(d2, interval, part_of_week)%>%summarize(average_steps = mean(steps))
View(set_4)
g <- ggplot(set_4, aes(intevral, average_steps))
g + geom_point()
g <- ggplot(set_4, aes(interval, average_steps))
g + geom_point()
g + geom_line()
g + geom_line() + facet_grid(set_4$part_of_week ~)
g + geom_line() + facet_grid(set_4$part_of_week ~,)
g + geom_line() + facet_grid(set_4$part_of_week)
set_4
g + geom_line() + facet_grid(part_of_week)
g + geom_line() + facet_grid(set4$part_of_week)
g + geom_line() + facet_grid(set_4$part_of_week)
g + geom_line() + facet_grid(set_4$part_of_week ~.)
g + geom_line() + facet_grid(.~set_4$part_of_week )
g + geom_line() + facet_grid(.~part_of_week )
g + geom_line() + facet_grid(part_of_week~.)
dataset_original <- tbl_df(read.csv('activity.csv'))
dataset_original <- transform(dataset1, date = as.Date(date, "%Y-%m-%d"))
dataset_original <- transform(dataset_original, date = as.Date(date, "%Y-%m-%d"))
total_per_day <- group_by(dataset_original, date)%>%summarize(total_steps = sum(steps))
total_per_day <- group_by(dataset_original, date)%>%summarize(total_steps = sum(steps)); total_per_day
hist(total_per_day$total_steps)
mean(total_per_day$total_steps, na.rm = T)
median(total_per_day$total_steps, na.rm = T)
average_per_interval <- group_by(dataset_original, interval)%>%summarize(average_steps = mean(steps, na.rm = T))
plot(average_per_interval$average_steps ~ set_2$interval, type = "l")
filter(average_per_interval, average_steps == max(average_steps))
sapply(dataset_original, function(x) length(which(is.na(x))))
dataset_2 <- dataset_original[,]
for (index in seq_along(dataset_2$steps)) {
if (is.na(dataset_2$steps[index])) {
dataset_2$steps[index] <- mean(dataset_2$steps[dataset_2$interval==dataset_2$interval[index]], na.rm = T)
}
}
total_per_day <- group_by(dataset_2, date)%>%summarize(total_steps = sum(steps))
hist(total_per_day$total_steps)
mean(total_per_day$total_steps)
median(total_per_day$total_steps)
dataset_2$part_of_week[weekdays(dataset_2$date)%in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")] = 'weekday'
dataset_2$part_of_week[weekdays(dataset_2$date)%in% c("Saturday", "Sunday")] = 'weekend'
average_per_interval_poweek <- group_by(dataset_2, interval, part_of_week)%>%summarize(average_steps = mean(steps))
g <- ggplot(average_per_interval_poweek, aes(interval, average_steps))
g + geom_line() + facet_grid(part_of_week~.)
###Read in data
?print
?melt
??dplyr
?print
methods("print")
total_per_day <- group_by(dataset_original, date)%>%summarize(total_steps = sum(steps)); total_per_day
hist(total_per_day$total_steps)
if (!file.exists('./activity.csv')) {
unzip('activity.zip', unzip = "unzip")
}
dataset_original <- tbl_df(read.csv('activity.csv'))
dataset_original <- transform(dataset_original, date = as.Date(date, "%Y-%m-%d"))
summary(dataset_original)
total_per_day <- group_by(dataset_original, date)%>%summarize(total_steps = sum(steps)); print(total_per_day, n = 61)
hist(total_per_day$tot_steps)
View(total_per_day)
hist(total_per_day$total_steps)
total_per_day <- group_by(dataset_original, date)%>%summarize(total_steps = sum(steps)); total_per_day
hist(total_per_day$total_steps)
